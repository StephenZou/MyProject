{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在神经网络中，每个节点基本都包括输入，输出，向前计算，向后计算，导数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构建一个节点对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs=inputs\n",
    "        self.value=None\n",
    "        self.outputs=[]\n",
    "        self.gradients={}\n",
    "        ## 创建当前节点与上一个节点的联系\n",
    "        for node in self.inputs:\n",
    "            node.outputs.append(self)\n",
    "    def forward(self):\n",
    "        \"\"\"前向计算\"\"\"\n",
    "        raise NotImplemented\n",
    "    def backward(self):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input继承Node\n",
    "class Input(Node):\n",
    "    def __init__(self,name=''):\n",
    "        Node.__init__(self,inputs=[])\n",
    "        self.name=name\n",
    "    def forward(self, value=None):\n",
    "        if value is not None:\n",
    "            self.value=value\n",
    "    def backward(self):\n",
    "        self.gradients={}\n",
    "        # 下一个节点的导数\n",
    "        for n in self.outputs:\n",
    "            grad_cost=n.gradients[self]\n",
    "            self.gradients[self]=grad_cost\n",
    "    def __repr__(self):\n",
    "        return 'Input Node:{}'.format(self.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造线性连接\n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        self.w_node=weights\n",
    "        self.x_node=nodes\n",
    "        self.b_node=bias\n",
    "        Node.__init__(self, inputs=[nodes, weights, bias])\n",
    "    def forward(self):\n",
    "        \"\"\"using numpy compute wx+b\"\"\"\n",
    "        self.value=np.dot(self.x_node.value,self.w_node.value)+self.b_node.value\n",
    "    def backward(self):\n",
    "        for node in self.outputs:\n",
    "            grad_cost=node.gradients[self]\n",
    "            self.gradients[self.w_node]=np.dot(self.x_node.value.T,grad_cost)\n",
    "            self.gradients[self.b_node]=np.dot(grad_cost*1,axis=0,keepdims=False)\n",
    "            self.gradients[self.x_ndoe]=np.dot(grad_cost,self.w_node.value.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self,node):\n",
    "        Node.__init__(self,[node])\n",
    "        self.x_node=node\n",
    "    def _sigmoid(self,x):\n",
    "        return 1./(1.+np.exp(-1*x))\n",
    "    def forward(self):\n",
    "        self.value=self._sigmoid(self.x_node.value)\n",
    "    def backward(self):\n",
    "        y=self.value\n",
    "        self.partial=y*(1-y)\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self.x_node]=grad_cost* self.partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y_true, y_hat):\n",
    "        self.y_true_node=y_true\n",
    "        self.y_hat_node = y_hat\n",
    "        Node.__init__(self, inputs=[y_true, y_hat])\n",
    "    def forward(self):\n",
    "        y_true_flatten=self.y_true_node.value.reshape(-1,1)\n",
    "        y_hat_flatten = self.y_hat_node.value.reshape(-1,1)\n",
    "        self.diff=y_true_flatten-y_hat_flatten\n",
    "        self.value=np.mean(self.diff**2)\n",
    "    def backward(self):\n",
    "        n=self.y_hat_node.value.shape[0]\n",
    "        self.gradients[self.y_true_node]=(2/n)*self.diff\n",
    "        self.gradients[self.y_hat_node] = (-2/n)*self.diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_one_batch(topological_sorted_graph):\n",
    "    for node in topological_sorted_graph:\n",
    "        node.forward()\n",
    "    for node in topological_sorted_graph[::-1]:\n",
    "        node.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sorted(data_with_value):\n",
    "    feed_dict=data_with_value\n",
    "    input_nodes=[n for n in feed_dict.keys()]\n",
    "    G={}\n",
    "    nodes=[n for n in input_nodes]\n",
    "    while len(nodes)>0:\n",
    "        n=nodes.pop()\n",
    "        if n not in G:\n",
    "            G[n]={'in':set(), 'out':set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m]={'in':set(),'out':set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "    L=[]\n",
    "    S=set(input_nodes)\n",
    "    while len(S)>0:\n",
    "        n=S.pop()\n",
    "        if isinstance(n,Input):\n",
    "            n.value=feed_dict[n]\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            if len(G[m]['in'])==0:\n",
    "                S.add(m)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainable_nodes, learning_rate=1e-2):\n",
    "    for t in trainable_nodes:\n",
    "        t.value += -1*learning_rate*t.grandients[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_=data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_=data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_2=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_=(X_-np.mean(X_,axis=0))/np.std(X_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features=X_.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_,b1_=np.random.randn(n_features, n_hidden), np.zeros(n_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2_,b2_=np.random.randn(n_hidden,1),np.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=Input(name='X'), Input(name='y')\n",
    "W1,b1=Input(name='W1'), Input(name='b1')\n",
    "W2,b2=Input(name='W2'), Input(name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_output=Linear(X,W1,b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid_output=Sigmoid(linear_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=Linear(sigmoid_output, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=MSE(y,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_node_with_value={\n",
    "    X:X_,\n",
    "    y:y_,\n",
    "    W1:W1_,\n",
    "    b1:b1_,\n",
    "    W2:W2_,\n",
    "    b2:b2_\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=topological_sorted(input_node_with_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Input Node:W2,\n",
       " Input Node:b2,\n",
       " Input Node:y,\n",
       " Input Node:X,\n",
       " Input Node:b1,\n",
       " Input Node:W1,\n",
       " <__main__.Linear at 0x1b6143c2ba8>,\n",
       " <__main__.Sigmoid at 0x1b6143da5c0>,\n",
       " <__main__.Linear at 0x1b6147a26a0>,\n",
       " <__main__.MSE at 0x1b6147b1080>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([29, 47, 40, 22, 36, 35,  8, 83, 58, 43])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(range(100),size=10, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(dictionary):\n",
    "    return topological_sorted(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses=[]\n",
    "epochs=100\n",
    "\n",
    "batch_size=64\n",
    "steps_per_epoch=X_.shape[0]//batch_size\n",
    "\n",
    "for i in range(epochs):\n",
    "    loss=0\n",
    "    for batch in range(steps_per_epoch):\n",
    "        X_batch,y_batch=resample(X_,y_,n_samples=batch_size)\n",
    "        X.value=X_batch\n",
    "        y.value=y_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dllearn",
   "language": "python",
   "name": "dllearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
